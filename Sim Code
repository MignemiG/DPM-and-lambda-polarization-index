rm(list=ls())
#---- http://www.stat.columbia.edu/~gelman/book/BDA3.pdf (p. 553) for Conv. monitoring advice 
setwd("C:/Users/39388/Dropbox/Il mio PC (LAPTOP-NO4UO9GH)/Desktop/Paper_UCL/SMA/Simulation 2")
library("mvtnorm")
library("multimode")
library("HDInterval")
library("invgamma") 
library("rstan")
library("bayesplot")

set.seed(010523)
J               = 250 #number of subjects
I               = 100  #number of raters
p               = 1   #number of covariates for fixed effects
q               = 1   #number of covariates for random effects
nMaxClusters    = 25  #see Gelman et al. 2013
Grid            = seq(-12,12,0.05)

#MCMC
nIter           = 50000
burnIn          = 5000
Thin            = 50

par(mfrow=c(1,1))
#...generative process

generateData <- function( mu, Q, w, s2e, alpha, beta, x, I, J ) {
  
  y              = matrix(0, nrow=I, ncol=J)
  IT             = matrix(0, nrow=I, ncol=1)
  u_ind          = matrix(0, nrow=I, ncol=1)
  ee             = matrix(0, nrow=I, ncol=J)
  
  for ( ii in 1:I ) {
    IT[ii]       = sample(length(w), 1, prob=w)
    u_ind[ii]    = mu[IT[ii]] + sqrt(Q[IT[ii]]) * rnorm(1)
    
    for ( tt in 1:J ) {
      ee[ii,tt]  = rnorm(1, 0, sqrt(s2e))
      y[ii,tt]   = alpha + u_ind[ii] + beta * x[ii,tt,1] + ee[ii,tt]
    }
  }
  
  list(y=y, u_ind=u_ind, I=IT, ee=c(t(ee)))
}
x_v             = array( 0, dim = c( I, J) )
for(ii in 1:I){
  x_v[ii,]      = rnorm(J,0,1)
}
cov             = array( c(x_v), dim = c( I, J, p ) )
#...
#...

m_1             = c(3, 3, 3)
m_2             = c(-3, -3, -3)
v1              = c(1, 0.5, 0.1)
v2              = v1 

true_mixture_m  = m_1[ff] * 0.5 + m_2[ff] * 0.5
true_mixture_var= 0.5 * (m_1[ff]^2 + v1[ff]) + 0.5 * (m_2[ff]^2 + v2[ff]) - true_mixture_m

#jpeg(file="originals_x.jpeg")
#par(mfrow=c(1,1))
#for(vv in 1:length(v1)){
#  curve(0.5*dnorm(x,m_1[vv],sqrt(v1[vv]))+0.5*dnorm(x,m_2[vv],sqrt(v2[vv])),from=Grid[1],to=Grid[length(Grid)],
#        main=paste("Component variance= ",v1[vv]),ylab="",xlab="")
#}
#dev.off()

#...simulations

for(ff in 1:length(v1)){
  
  m1              = m_1[ff]
  m2              = m_2[ff]
  #m3              = m_3[ff]
  sb1             = v1[ff]
  sb2             = v2[ff]
  synt_data       = generateData( mu=c(m1,m2), Q=c(sb1,sb2), w=c(0.5,0.5),
                                  s2e=0.4, alpha=0,beta=2, x=cov, I=I, J=J) 
  
  write.csv(synt_data, file=paste(paste("synt_data_",ff),".csv"))
  
  sample_mixture_m  = mean(synt_data$u_ind[which(synt_data$I==1)]) * 
    (length(synt_data$u_ind[which(synt_data$I==1)])/I) +
    mean(synt_data$u_ind[which(synt_data$I==2)]) * 
    (length(synt_data$u_ind[which(synt_data$I==2)])/I)
  
  sample_mixture_var= (length(synt_data$u_ind[which(synt_data$I==1)])/I) * 
    (mean(synt_data$u_ind[which(synt_data$I==1)])^2 + 
       var(synt_data$u_ind[which(synt_data$I==1)])) + 
    (length(synt_data$u_ind[which(synt_data$I==2)])/I) * 
    (mean(synt_data$u_ind[which(synt_data$I==2)])^2 + 
       var(synt_data$u_ind[which(synt_data$I==2)]))
  - sample_mixture_m
  
  ee_sample_var = var(synt_data$ee)
  
 
  
  #...
  
  x               = array( 0, dim= c( I * J, p ) )
  for( pp in 1:p){
    x[,pp]        = c(t(cov[,,pp]))
  }
  
  y               = c(t(synt_data$y))
  
  
  z               = array( 0, dim = c( I * J, q ) )
  z_v             = array( 0, dim = c( I, J) )
  for(ii in 1:I){
    z_v[ii,]      = 1
  }
  rand             = array( c(z_v), dim = c( I, J, q ) )
  for( qq in 1:q){
    z[,pp]        = c(t(rand[,,qq]))
  }
  
  Z               = array( 0, dim = c( I * J, I * q ) )  # ??? ??? 
  
  
  for(ii in 1:I){
    for(mm in 1:(I * q)){
      if(mm > p*(ii-1)  && mm < q*ii+1){
        for(kk in (J*ii-J+1):(J*ii)){
          Z[kk,mm]  = z[kk]
        }
      }
    } 
  }
  
  
  
  #Hyper-priors
  #...Fixed Effectsd
  m_beta          = rep( 0, p )
  sigma_s_2       = rep( 1000, p )
  a_beta          = 0.005
  b_beta          = 0.005
  #...Random Effects
  m_0             = array( 0, dim = q )
  sigma_s_0       = array( 100, dim = q )
  a_0             = 0.5
  b_0             = 0.5
  a_b             = 0.0001
  b_b             = 0.0001
  a_alpha         = 2
  b_alpha         = 2
  #...Noise Term
  a_e             = 0.005
  b_e             = 0.005
  
  
  
  #...... preallocation 
  mu_beta               = array( 0, dim = c( nIter+1, p) )
  mu_beta_s             = array( 0, dim = c( nIter+1, p) )
  sigma_beta            = array( 0, dim = c( nIter+1, p) )
  Sigma_beta            = array( 0, dim = c( p, p ) )
  m_beta                = array( 0, dim = c( nIter+1, p) )
  beta                  = array( 0, dim = c( nIter+1, p) )
  
  mu_0                  = array( 0, dim = c( nIter+1, q) )
  sigma_0               = array( 0, dim = c( nIter+1, q) )
  sigma_b               = array( 0, dim = c( nIter+1, q, nMaxClusters) )
  Sigma_b               = array( 0, dim = c( p, q, nIter+1) )
  theta                 = array( 0, dim = c( I, q, nIter+1) )
  sigma_ii              = array( 0, dim = c( I, q, nIter+1) )
  b                     = array( 0, dim = c( I, q, nIter+1) )
  
  phi                   = array( 0, dim = c( nMaxClusters, q, nIter+1) )
  mean_b                = array( 0, dim = c( nMaxClusters, q, nIter+1) )
  c                     = array( 0, dim = c( I, nIter+1) )
  ni_c                  = array( 0, dim = c( nMaxClusters, nIter+1) )
  alpha_0               = array( 0, dim = c( 1, nIter+1) )
  pi_c                  = array( 0, dim = c( nIter+1,nMaxClusters) )
  nu                    = array( 0, dim = c( nMaxClusters, nIter+1) )
  sigma_2               = array( 0, dim =  c( 1, nIter+1) )
  
  Mean_mixt             = array( 0, dim =  c( 1, nIter+1) )
  Var_mixt              = array( 0, dim =  c( 1, nIter+1) )
  lambda                = array( 0, dim =  c( 1, nIter+1) )
  
  mean_mix              = array( 0, dim =  c( 1, nIter+1) )
  var_mix               = array( 0, dim =  c( 1, nIter+1) )
  approx_ICC            = array( 0, dim =  c( 1, nIter+1) )
  
  p_Grid                = array( 0, dim = c( length(Grid), nIter+1) )
  
  #------ Initial Quantities
  sigma_beta[1,]        = 1
  mu_beta[1,]           = 0
  mu_0[1,]              = 0
  sigma_0[1,]           = 2
  sigma_b[1,,]          = 2   
  pi_c[1,]              = rep(1/nMaxClusters,nMaxClusters)
  c[,1]                 = sample(1:nMaxClusters, I, prob=pi_c[1,], replace = TRUE)
  phi[,,1]              = rmvnorm(nMaxClusters, mu_0[1,], sqrt(sigma_0[1,]*diag(q)) ) 
  for(hh in 1:nMaxClusters){
    for(ii in 1:I){
      if(c[ii,1] == hh){
        b[ii,,1]         = rmvnorm(q, phi[hh,,1], sigma_b[1,,hh]*diag(q) )
      }
    }
  }
  alpha_0[1]             = 1
  sigma_2[1]             = 0.8   
  
  for(ii in 1:I){
    for(hh in 1:nMaxClusters){
      if(c[ii,1] == hh){
        ni_c[hh,1]       =  ni_c[hh,1]+1
      }
    }
  }
  mean_mix[1]            = 0
  var_mix[1]             = 1
 
  
  
  
  
  
  
   for(kk in 1:nIter){
    
    #------Update parameters referring to fixed effects
    
    Sigma_beta              = solve( solve(sigma_beta[kk,]*diag(p)) + t(x) %*% x / sigma_2[kk] )
    
    mu_beta_s[kk,]          = solve( solve(sigma_beta[kk,]*diag(p)) + t(x) %*% x / sigma_2[kk] ) *
      ( solve(sigma_beta[kk,]*diag(p)) * mu_beta[kk,] + t(x) %*% ( y - Z%*%b[,,kk] )/ sigma_2[kk] ) 
    
    beta[kk+1,]             = rmvnorm( 1, mu_beta_s[kk,], sqrt(Sigma_beta))           
    
    for(rr in 1:p){
      mu_beta[kk+1,rr]      = rnorm( 1, solve(1/sigma_beta[kk,rr]+1/sigma_s_2[rr]) * 
                                       (beta[kk+1, rr]/sigma_beta[kk,rr] + m_beta[rr]/sigma_s_2[rr]) , 
                                     sqrt(solve(1/sigma_beta[kk,rr]+1/sigma_s_2[rr])) )
      
      sigma_beta[kk+1,rr]   = rinvgamma(1, a_beta + 0.5 , b_beta + 0.5*(beta[kk+1,rr]-mu_beta[kk+1,rr])^2 )
      
    }
    #------Update parameters referring to random effects
    
    #Sigma_b[,,kk]           = sigma_b[kk,]*diag(q)
    
    for(ii in 1:I){
      Sigma_bc              = sigma_b[kk,,c[ii,kk]]*diag(q)
      Sigma_b_i             = solve( solve(Sigma_bc) + t(z[(J*ii-J+1):(J*ii)]) %*% z[(J*ii-J+1):(J*ii)] / sigma_2[kk])
      
      mu_b_i                = solve( solve(Sigma_bc) + t(z[(J*ii-J+1):(J*ii)]) %*% z[(J*ii-J+1):(J*ii)] / sigma_2[kk]) *
        ( solve(Sigma_bc) * theta[ii,,kk] + t(z[(J*ii-J+1):(J*ii)]) %*% ( y[(J*ii-J+1):(J*ii)] - x[(J*ii-J+1):(J*ii)]*beta[kk+1,] )/ sigma_2[kk] )
      
      b[ii,,kk+1]           = rmvnorm( 1, mu_b_i, sqrt(Sigma_b_i))
    }
    
    
    
    for(hh in 1:nMaxClusters){
      if(ni_c[hh,kk]<1){
        phi[hh,,kk+1]       = rmvnorm(1, mu_0[kk,], sqrt(sigma_0[kk,]*diag(q)))
        sigma_b[kk+1,,hh]   = rinvgamma(1, a_b , b_b ) 
        
      } else{
        for(qq in q){
          index             = which(c[,kk] == hh)
          mean_b            = mean(b[index , qq, kk+1]) 
          mu_0_star         = solve( ni_c[hh,kk]/sigma_b[kk,qq,hh]+1/sigma_0[kk,qq] ) * ( ni_c[hh,kk]/sigma_b[kk,qq,hh] * mean_b+mu_0[kk,qq]/sigma_0[kk,qq] )
          sigma_0_star      = solve( ni_c[hh,kk]/sigma_b[kk,qq,hh]+1/sigma_0[kk,qq] )
          
          phi[hh,qq,kk+1]   = rnorm(1, mu_0_star, sqrt(sigma_0_star))
   sigma_b[kk+1,qq,hh]      = rinvgamma(1, a_b + 0.5 * ni_c[hh,kk], b_b + 0.5 * sum((b[index , qq, kk+1] - phi[hh,qq,kk+1])^2) ) 
        }
      }
    }
    
    
    
    #----- Subjects Allocation
    for(ii in 1:I){
      pi                    = array( 0, dim = c( I, nMaxClusters) )
      for(hh in 1:nMaxClusters){
        pi[ii,hh]           = log(pi_c[kk,hh]) + dnorm( b[ii,,kk+1], phi[hh,,kk+1], sqrt(sigma_b[kk+1,,hh]), log = TRUE )
      }
      
      pro                   = exp(pi[ii,]-max(pi[ii,]))/
        sum(exp(pi[ii,]-max(pi[ii,])))                        #Log-weight trick to get rid of numerical problems
      
      c[ii,kk+1]            = sample(1:nMaxClusters, 1 , prob=pro)
      theta[ii,,kk+1]       = phi[c[ii,kk+1],,kk+1] 
      sigma_ii[ii,,kk+1]    = sigma_b[kk+1,,c[ii,kk+1]]
    }
    
    #----- Stick-Breaking
    for(hh in 1:nMaxClusters){
      ni_c[hh,kk+1] = length(which(c[,kk+1] == hh))
        }
    
    if (alpha_0[kk] == 0){
      alpha_0[kk]           = 0.001                                                 # to avoid an improper beta per the empty clusters
    }
    for( jj in 1:nMaxClusters ){
      if( jj < nMaxClusters ){
        nl                  = ni_c[jj+1:nMaxClusters]
        nu[jj,kk+1]         = rbeta(1, 1 + ni_c[jj], alpha_0[kk] + sum(nl))
        
      } else{
        nu[jj,kk+1]         = 1
      }
      nu_l                  = nu[1:(jj-1),kk+1]
      pi_c[kk+1,jj]         = nu[jj,kk+1] * prod(1 - nu_l)
    }
    
    alpha_0[kk+1]           = rgamma(1, a_alpha + nMaxClusters -1, b_alpha - sum(log(1-nu[1:(nMaxClusters-1)])))
    
    
    #----- Base measure parameters 
    for(qq in 1:q){
      mu_0[kk+1,qq]         = rnorm(1, solve(I/sigma_0[kk,qq] + 1/sigma_s_0[qq]) * 
                                      (I/sigma_0[kk,qq] * mean(theta[,qq,kk+1])  + m_0[qq]/sigma_s_0[qq]),
                                    sqrt(solve(I/sigma_0[kk,qq] + 1/sigma_s_0[qq])))
      
      
      sigma_0[kk+1,qq]      = rinvgamma(1, a_0 + 0.5 * I, b_0 + 0.5 * sum((theta[,qq,kk+1] - mu_0[kk+1,qq])^2) )
    }
    
    
    #-----Update the error variance # univariate fixed and random intercept
    sigma_2[kk+1]           = rinvgamma(1, a_e + 0.5 * I * J , b_e + 0.5 * sum((y - x * beta[kk+1,] - Z%*%b[,1,kk+1])^2) )
    
    #----- Parametric Mixture monitoring
    
    s_grid                  = array( 0, dim = c( I, length(Grid)) )
    
    for(ii in 1:I){
      
      s_grid[ii,]            = dnorm(Grid, theta[ii,,kk+1],sqrt(sigma_b[kk+1,1,c[ii,kk+1]]))
    }
    
    mean_mix[kk+1]           = mean(theta[,,kk+1])
    var_mix[kk+1]            = mean(sigma_ii[,,kk+1] + theta[,,kk+1]^2)-mean(theta[,,kk+1]) #####
    approx_ICC[kk+1]         = var_mix[kk+1]/(var_mix[kk+1]+sigma_2[kk+1])
    
    p_Grid[,kk+1]           = apply(s_grid, 2, mean)
    
    modes                   = array( 0, dim = c( 1, length(Grid)) )
    anti_m                  = array( -0.01, dim = c( 1, length(Grid)) )
    climb                   = 1
    for(gg in 1:(length(Grid)-1)){
      if(climb == 1 ){
        
        if(p_Grid[gg+1,kk+1] > p_Grid[gg,kk+1]){
          prop_m            = p_Grid[gg+1,kk+1]
        }
        if(p_Grid[gg+1,kk+1] < p_Grid[gg,kk+1]){
          modes[gg]         = prop_m
          climb             = -1
        }
        
      } else{
        if(p_Grid[gg+1,kk+1] < p_Grid[gg,kk+1]){
          prop_a          = p_Grid[gg+1,kk+1]
        }
        if(p_Grid[gg+1,kk+1] > p_Grid[gg,kk+1]){
          anti_m[gg]      = prop_a
          climb           = 1
        }
      }
    }
    
    modes                   = modes[which(modes != 0)]
    anti_m                  = anti_m[which(anti_m > -0.01)]
    lambda[kk+1]            = log(mean(modes)/mean(anti_m))
    if(lambda[kk+1]=="NaN"){
      lambda[kk+1]         = 0
    }
    
    #----- Partial cluster approach 
    
    
    
    if (kk %% 100 == 0) {
      par(mfrow=c(2,1))
      print(paste(paste(paste("iteration: ",kk,sep="")," of ", nIter, sep="")," complete.",sep="", ff))
      plot(Grid,p_Grid[,kk+1],type="l",ylab="",main=paste("Mixture monitoring, iteration ", kk),
           sub=paste("lambda= ", lambda[kk+1]),ylim=c(0,1.3))
      for(ii in 1:I){
        curve(dnorm( x, theta[ii,,kk+1],sqrt(sigma_b[kk+1,1,c[ii,kk+1]])),from=min(Grid),to=max(Grid), add = TRUE, col = "violet")
      }
      plot(table(theta[,,kk+1]),xlim=c(min(Grid),max(Grid)),ylab="",xaxt = "n",main=paste("N group= ",length(table(theta[,,kk+1]))))
    }
    
    
    
  }
  
  
  #---- Storage 
  write.csv(apply(p_Grid[,which (burnIn:nIter %% Thin == 0) + burnIn],1,mean), file=paste(paste("Grid_post_",ff),".csv"))
  write.csv(b[,1,which (burnIn:nIter %% Thin == 0) + burnIn], file=paste(paste("b_post_",ff),".csv"))
  write.csv(lambda[which (burnIn:nIter %% Thin == 0) + burnIn],file=paste(paste("lambda_post_",ff),".csv"))
  write.csv(beta[which (burnIn:nIter %% Thin == 0) + burnIn],file=paste(paste("beta_post_",ff),".csv"))
  write.csv(mu_beta[which (burnIn:nIter %% Thin == 0) + burnIn,1], file=paste(paste("mu_beta_post_",ff),".csv"))
  write.csv(sigma_beta[which (burnIn:nIter %% Thin == 0) + burnIn,], file=paste(paste("sigma_beta_post_",ff),".csv"))
  write.csv(mu_0[which (burnIn:nIter %% Thin == 0) + burnIn,1], file=paste(paste("mu_0_post_",ff),".csv"))
  write.csv(sigma_0[which (burnIn:nIter %% Thin == 0) + burnIn,1], file=paste(paste("sigma_0_post_",ff),".csv"))
  ##write.csv(sigma_b[which (burnIn:nIter %% Thin == 0) + burnIn,1,], file=paste(paste("sigma_b_post_",ff),".csv"))
  write.csv(sigma_2[which (burnIn:nIter %% Thin == 0) + burnIn], file=paste(paste("sigma_2_post_",ff),".csv"))
  write.csv(alpha_0[which (burnIn:nIter %% Thin == 0) + burnIn], file=paste(paste("alpha_0_post_",ff),".csv"))
  
  
  #---- Some Plots ???
  par(mfrow=c(1,1))
  
  
  #--- GRID
  jpeg(file=paste(paste("Grid_post_",ff),".jpeg"))
  plot(Grid,apply(p_Grid[,which (burnIn:nIter %% Thin == 0) + burnIn],1,mean),type="l",
       main="Mixture monitoring",ylab="") 
  points(synt_data$u_ind,rep(0,length(synt_data$u_ind)),pch=8,col="red")
  abline(v=c(m1,m2),col="red",lty=2)
  dev.off()
  #legend("topright", legend=c("True values","True cluster mean","Estimated Grid"),col=c("red","red","black"),pch=8,lty=c(2,1))
  
  #...HPD Intervals  
  par(mfrow=c(1,1))
  jpeg(file=paste(paste("Grid_HDP_post_",ff),".jpeg"))
  plot(Grid,apply(p_Grid[,which (burnIn:nIter %% Thin == 0) + burnIn],1,mean),type="l",
       main="Grid density",ylab="",xlab="",xaxt = "n") 
  l_k<-apply(p_Grid[,which (burnIn:nIter %% Thin == 0) + burnIn],1,mean)
  em<- list(x = Grid[which(l_k > 0.01)], y = l_k[which(l_k > 0.01)], bw=0.1, n=length(Grid[which(l_k > 0.01)]))
  attr(em, "class") <- "density"
  (hdiD <- hdi(em, allowSplit=TRUE,credMass = 0.90))
  (ht <- attr(hdiD, "height"))
  #segments(hdiD[, 1], ht, hdiD[, 2], ht, lwd=4, col='blue', lend='butt')
  #abline(h=ht,lty=2,col="blue")
  abline(v=c(hdiD[, 1],hdiD[, 2]),lty=2,col="deeppink")
  axis(1,at=c(round(hdiD[, 1],3),round(hdiD[, 2],3)))
  for(ww in 1:length(hdiD[, 1])){
    l <- min(which(em$x >= hdiD[ww, 1]))
    h <- max(which(em$x < hdiD[ww, 2]))
    polygon(c(em$x[c(l, l:h, h)]),
            c(0, em$y[l:h], 0),
            col = "deeppink",
            density = 30, angle = 45)
  }
  dev.off()  
  write.csv(hdiD,file=paste(paste("HPD Intervals Grid_",ff),".csv"))
  
  
  #--- b Posterior Samples 
  jpeg(file=paste(paste("b_post_",ff),".jpeg"))
  plot(density(b[,1,which (burnIn:nIter %% Thin == 0) + burnIn]),col="blue",main="KDE of posterior samples")
  points(synt_data$u_ind,rep(0,length(synt_data$u_ind)),pch=8,col="red")
  abline(v=c(m1,m2),col="red",lty=2)
  dev.off()
  
  #...HPD Intervals
  jpeg(file=paste(paste("b_HDP_post_",ff),".jpeg"))
  plot(density(b[,1,which (burnIn:nIter %% Thin == 0) + burnIn]),
       col="blue",main="KDE of posterior samples - 95% HPD",xlab="")
  ee <- density(b[,1,which (burnIn:nIter %% Thin == 0) + burnIn])
  (hdiD <- hdi(ee, allowSplit=TRUE,credMass = 0.90))
  (ht <- attr(hdiD, "height"))
  segments(hdiD[, 1], ht, hdiD[, 2], ht, lwd=4, col='blue', lend='butt')
  abline(h=ht,lty=2,col="blue")
  abline(v=c(hdiD[, 1],hdiD[, 2]),lty=2,col="blue")
  for(ww in 1:length(hdiD[, 1])){
    l <- min(which(ee$x >= hdiD[ww, 1]))
    h <- max(which(ee$x < hdiD[ww, 2]))
    polygon(c(ee$x[c(l, l:h, h)]),
            c(0, ee$y[l:h], 0),
            col = "blue",
            density = 10, angle = 45)
  }
  dev.off()
  write.csv(hdiD,file=paste(paste("HPD Intervals b_",ff),".csv"))
  
  #legend("topright", legend=c("True values","True cluster mean","Estimated KDE"),col=c("red","red","blue"),lty=c(1,2,1))
  
  
  #--- LAMBDA
  jpeg(file=paste(paste("lambda_post_",ff),".jpeg"))
  plot(density(lambda[which (burnIn:nIter %% Thin == 0) + burnIn]),main="",xlab="")
  title(main=bquote(lambda), cex.main = 2.3, font.main= 4)
  dev.off()
  #credInt_lambda            = quantile(lambda[which (burnIn:nIter %% Thin == 0) + burnIn],c(.05,.95))
  #abline(v=credInt_lambda,lty=2,col="red")
  
  #...HPD Intervals
  jpeg(file=paste(paste("lambda_HDP_post_",ff),".jpeg"))
  plot(density(lambda[which (burnIn:nIter %% Thin == 0) + burnIn]),
       col="blue",main="KDE of posterior samples - 95% HPD",xlab="",xlim=c(0,50))
  ee <- density(lambda[which (burnIn:nIter %% Thin == 0) + burnIn])
  (hdiD <- hdi(ee, allowSplit=TRUE,credMass = 0.88))
  (ht <- attr(hdiD, "height"))
  segments(hdiD[, 1], ht, hdiD[, 2], ht, lwd=4, col='blue', lend='butt')
  abline(h=ht,lty=2,col="blue")
  abline(v=c(hdiD[, 1],hdiD[, 2]),lty=2,col="blue")
  for(ww in 1:length(hdiD[, 1])){
    l <- min(which(ee$x >= hdiD[ww, 1]))
    h <- max(which(ee$x < hdiD[ww, 2]))
    polygon(c(ee$x[c(l, l:h, h)]),
            c(0, ee$y[l:h], 0),
            col = "blue",
            density = 30, angle = 45)
  }
  dev.off()
  
  write.csv(hdiD,file=paste(paste("HPD Intervals lambda_",ff),".csv"))
  
  
  #...lambda based computed only over the the post Grid (not at each iter.)
  d_Grid                  = apply(p_Grid[,which (burnIn:nIter %% Thin == 0) + burnIn],1,mean)
  modes                   = array( 0, dim = c( 1, length(Grid)) )
  anti_m                  = array( -0.01, dim = c( 1, length(Grid)) )
  climb                   = 1
  for(gg in 1:(length(Grid)-1)){
    if(climb == 1 ){
      
      if(d_Grid[gg+1] > d_Grid[gg]){
        prop_m            = d_Grid[gg+1]
      }
      if(d_Grid[gg+1] < d_Grid[gg]){
        modes[gg]         = prop_m
        climb             = -1
      }
      
    } else{
      if(d_Grid[gg+1] < d_Grid[gg]){
        prop_a          = d_Grid[gg+1]
      }
      if(d_Grid[gg+1] > d_Grid[gg]){
        anti_m[gg]      = prop_a
        climb           = 1
      }
    }
  }
  
  modes                   = modes[which(modes != 0)]
  anti_m                  = anti_m[which(anti_m > -0.01)]
  lambda_post_overall     = log(mean(modes)/mean(anti_m))
  if(lambda_post_overall=="NaN"){
    lambda_post_overall   = 0
  }
  write.csv(lambda_post_overall,file=paste(paste("lambda_post_over_",ff),".csv"))
  
  #---- Mixture Parameters 
  #par(mfrow=c(1,2))
  #jpeg(file=paste(paste("Mixture Par",ff),".jpeg"))
  #
  #plot(density(mean_mix[which (burnIn:nIter %% Thin == 0) + burnIn]), main="Post mixture mean")
  #abline(v=true_mixture_m,col="red")
  #abline(v=sample_mixture_m, col="blue")
  #abline(v=mean(mean_mix[which (burnIn:nIter %% Thin == 0) + burnIn]),col="black")
  #legend("topright", legend=c("True value", "Sample mean", "Post mean"),col=c("red","blue","black"),lty=1)
  #
  #plot(density(var_mix[which (burnIn:nIter %% Thin == 0) + burnIn]), main="Post mixture variance")
  #abline(v=true_mixture_var,col="red") 
  #abline(v=sample_mixture_var, col="blue")
  #abline(v=mean(var_mix[which (burnIn:nIter %% Thin == 0) + burnIn]),col="black")
  #legend("topright", legend=c("True value", "Sample mean", "Post mean"),col=c("red","blue","black"),lty=1)
  #dev.off()
  
  #--- HPD mix mean
  #par(mfrow=c(1,1))
  #jpeg(file=paste(paste("Mixture mean HPD",ff),".jpeg"))
  #plot(density(mean_mix[which (burnIn:nIter %% Thin == 0) + burnIn]),main="",xlab="",xaxt = "n")
  #title(main="mix mean HPD", cex.main = 1.3, font.main= 4)
  #ee <- density(mean_mix[which (burnIn:nIter %% Thin == 0) + burnIn])
  #(hdiD <- hdi(ee, allowSplit=TRUE,credMass = 0.90))
  #(ht <- attr(hdiD, "height"))
  ##segments(hdiD[, 1], ht, hdiD[, 2], ht, lwd=4, col='deeppink', lend='butt')
  ##abline(h=0,lty=2,col="blue")
  #abline(v=c(hdiD[, 1],hdiD[, 2]),lty=2,col="deeppink")
  #axis(1,at=c(round(hdiD[, 1],3),round(hdiD[, 2],3)))
  #for(ww in 1:length(hdiD[, 1])){
  #  l <- min(which(ee$x >= hdiD[ww, 1]))
  #  h <- max(which(ee$x < hdiD[ww, 2]))
  #  polygon(c(ee$x[c(l, l:h, h)]),
  #          c(0, ee$y[l:h], 0),
  #          col = "deeppink",
  #          density = 30, angle = 45)
  #}
  #abline(v=true_mixture_m,col="red")
  #abline(v=sample_mixture_m, col="blue")
  #legend("topleft", legend=c("True value", "Sample est"),col=c("red","blue"),lty=1)
  #
  #dev.off()
  
  #--- HPD mix var
 #par(mfrow=c(1,1))
 #jpeg(file=paste(paste("Mixture var HPD",ff),".jpeg"))
 #plot(density(var_mix[which (burnIn:nIter %% Thin == 0) + burnIn]),main="",xlab="",xaxt = "n")
 #title(main="mix var HPD", cex.main = 1.3, font.main= 4)
 #ee <- density(var_mix[which (burnIn:nIter %% Thin == 0) + burnIn])
 #(hdiD <- hdi(ee, allowSplit=TRUE,credMass = 0.90))
 #(ht <- attr(hdiD, "height"))
 ##segments(hdiD[, 1], ht, hdiD[, 2], ht, lwd=4, col='deeppink', lend='butt')
 ##abline(h=0,lty=2,col="blue")
 #abline(v=c(hdiD[, 1],hdiD[, 2]),lty=2,col="deeppink")
 #axis(1,at=c(round(hdiD[, 1],3),round(hdiD[, 2],3)))
 #for(ww in 1:length(hdiD[, 1])){
 #  l <- min(which(ee$x >= hdiD[ww, 1]))
 #  h <- max(which(ee$x < hdiD[ww, 2]))
 #  polygon(c(ee$x[c(l, l:h, h)]),
 #          c(0, ee$y[l:h], 0),
 #          col = "deeppink",
 #          density = 30, angle = 45)
 #}
 #abline(v=true_mixture_var,col="red")
 #abline(v=sample_mixture_var, col="blue")
 #legend("topleft", legend=c("True value", "Sample est"),col=c("red","blue"),lty=1)
 #
 #dev.off()
  
  
  
  
  #---- approx_ICC 
 #par(mfrow=c(1,1))
 #jpeg(file=paste(paste("approx_ICC HPD",ff),".jpeg"))
 #plot(density(approx_ICC[which (burnIn:nIter %% Thin == 0) + burnIn]),main="",xlab="",xaxt = "n",
 #     xlim=c(0.92,0.99))
 #title(main="approx_ICC HPD", cex.main = 1.3, font.main= 4)
 #ee <- density(approx_ICC[which (burnIn:nIter %% Thin == 0) + burnIn])
 #(hdiD <- hdi(ee, allowSplit=TRUE,credMass = 0.95))
 #(ht <- attr(hdiD, "height"))
 ##segments(hdiD[, 1], ht, hdiD[, 2], ht, lwd=4, col='deeppink', lend='butt')
 ##abline(h=0,lty=2,col="blue")
 #abline(v=c(hdiD[, 1],hdiD[, 2]),lty=2,col="deeppink")
 #cex.axis = 0.5
 #axis(1,at=c(round(hdiD[, 1],3),round(hdiD[, 2],3)))
 #for(ww in 1:length(hdiD[, 1])){
 #  l <- min(which(ee$x >= hdiD[ww, 1]))
 #  h <- max(which(ee$x < hdiD[ww, 2]))
 #  polygon(c(ee$x[c(l, l:h, h)]),
 #          c(0, ee$y[l:h], 0),
 #          col = "deeppink",
 #          density = 20, angle = 45)
 #}
 #abline(v=true_mixture_var/(true_mixture_var+0.4),col="red")
 #abline(v=sample_mixture_var/(sample_mixture_var+var(synt_data$ee)), col="blue")
 #legend("topleft", legend=c("True value", "Sample est"),col=c("red","blue"),lty=1)
 #
 #
 #write.csv(hdiD,file=paste(paste("HPD Intervals ICC_",ff),".csv"))
  
  #---- Trace Plot and storage
  par(mfrow=c(2,2))
  
  jpeg(file=paste(paste("Trace_1_4_",ff),".jpeg"))
  
  
  
  plot(mu_beta[which (burnIn:nIter %% Thin == 0) + burnIn,1],type="l",main="Trace Plot mu_beta",ylab="",
       sub="nIter = 55000, burnIn = 5000, Thin = 50")
  
  plot(sigma_beta[which (burnIn:nIter %% Thin == 0) + burnIn,1],type="l",main="Trace Plot sigma_beta",ylab="",
       sub="nIter = 55000, burnIn = 5000, Thin = 50")
  
  
  plot(mu_0[which (burnIn:nIter %% Thin == 0) + burnIn,1],type="l",main="Trace Plot mu_0",ylab="",
       sub="nIter = 55000, burnIn = 5000, Thin = 50")
  dev.off()
  
  
  jpeg(file=paste(paste("Trace_5_8_",ff),".jpeg"))
  
  plot(sigma_0[which (burnIn:nIter %% Thin == 0) + burnIn,1],type="l",main="Trace Plot sigma_0",ylab="",
       sub="nIter = 55000, burnIn = 5000, Thin = 50")
  
  
  #plot(sigma_b[which (burnIn:nIter %% Thin == 0) + burnIn,1],type="l",main="Trace Plot sigma_b",ylab="",
      # sub="nIter = 55000, burnIn = 5000, Thin = 50")
  #abline(h=0.2,col="red")
  
  
  plot(sigma_2[which (burnIn:nIter %% Thin == 0) + burnIn],type="l",main="Trace Plot sigma_2",ylab="",
       sub="nIter = 55000, burnIn = 5000, Thin = 50",ylim=c(0.3,0.50))
  abline(h=0.4,col="red")
  
  plot(alpha_0[which (burnIn:nIter %% Thin == 0) + burnIn],type="l",main="Trace Plot alpha_0",ylab="",
       sub="nIter = 55000, burnIn = 5000, Thin = 50")
  
  dev.off()
  
  
  par(mfrow=c(1,1))
  jpeg(file=paste(paste("Trace_alpha_",ff),".jpeg"))
  plot(lambda[which (burnIn:nIter %% Thin == 0) + burnIn],type="l",main="Trace Plot lambda",ylab="",
       sub="nIter = 55000, burnIn = 5000, Thin = 50")
  dev.off()
  
  #par(mfrow=c(2,1))
  #jpeg(file=paste(paste("Trace_mixture_par_",ff),".jpeg"))
  #plot(mean_mix[which (burnIn:nIter %% Thin == 0) + burnIn],type="l",
  #     main=paste("Trace Plot mu_mix ",round(mean(mean_mix[which (burnIn:nIter %% Thin == 0) + burnIn]),2)),ylab="",
  #     sub="nIter = 55000, burnIn = 5000, Thin = 50")
  #abline(h=true_mixture_m,col="red")
  #legend("topright", legend=c("True value"),col="red",lty=1)
  
  #plot(var_mix[which (burnIn:nIter %% Thin == 0) + burnIn],type="l",
  #     main=paste("Trace Plot var_mix ",round(mean(var_mix[which (burnIn:nIter %% Thin == 0) + burnIn]),2)),ylab="",
  #     sub="nIter = 55000, burnIn = 5000, Thin = 50")
  #abline(h=true_mixture_var,col="red")
  #legend("topright", legend=c("True value"),col="red",lty=1)
  #dev.off()
  
  par(mfrow=c(2,5))
  jpeg(file=paste(paste("Trace_raters_",ff),".jpeg"))
  for(ii in 1:10){
    plot(b[ii,,which (burnIn:nIter %% Thin == 0) + burnIn],type="l",main=paste("Trace Plot rater", ii),ylab="",
         sub="nIter = 55000, burnIn = 5000, Thin = 50")
    abline(h=synt_data$u_ind[ii],col="red")
    legend("topright", legend=c("True value"),col="red",lty=1)
  }
  dev.off()
  
  par(mfrow=c(1,1))
  true_raters_bias = synt_data$u_ind
  post_raters_bias = apply(b[,,which (burnIn:nIter %% Thin == 0) + burnIn],1,mean)
  
  jpeg(file=paste(paste("Random_effect_recovery_",ff),".jpeg"))
  plot(true_raters_bias, pch=19, col="red", main="True - estimated raters' bias",ylim=c(-6,8))
  points(post_raters_bias, col="black",cex=2)
  legend("topright", legend=c("True value", "Post value"),col=c("red", "black"),pch=c(19,1))
  dev.off()
  
  
  #...a bit of rest ??? 
  Sys.sleep(0.5)
  print("I'm starting with STAN ♥")


#------------------------------------------------------------------------------
setwd("C:/Users/39388/Dropbox/Il mio PC (LAPTOP-NO4UO9GH)/Desktop/Paper_UCL/SMA/Simulation 2")


Warmup          = 1000 
Iter            = 2000
Chains          = 4
Cores           = 4 
Thin            = 2

#K               = 2 # Number of Groups

#Data            = read.csv(file = paste(paste("synt_data_",ff),".csv"))
#y               = c(t(synt_data$y))

x               = as.vector(x)
ll              = as.vector(Z%*%rep(1:I))
stan.data       = list(I, J, I * J, y, x, ll)
names(stan.data)= c("I","J","N","y","x","ll")

print("I'm starting with STAN ♥")

fit.model       = stan(file = "Sim_stan.stan", data = stan.data, warmup = Warmup, iter = Iter, chains =Chains,
                       cores = Cores, thin = Thin, sample_file = paste(paste("sample_stan_",ff),".csv"))

saveRDS(fit.model, file =  paste("fit_Model_",ff,".rds"))

#fit_cp=readRDS(file =  paste("fit_Model_mix_",ff,".rds"))
fit_ss <- extract(fit.model, permuted = TRUE) 
#...Plot 
setwd("C:/Users/39388/Dropbox/Il mio PC (LAPTOP-NO4UO9GH)/Desktop/Paper_UCL/SMA/Simulation 2/Stan_plot")

#--------------------------- Diagnostics ---------------------------------------
#plot(fit.model , plotfun = "trace",pars="beta", inc_warmup = FALSE)
#Sys.sleep(1.5)
#plot(fit.model , plotfun = "trace",pars="sigma_u", inc_warmup = FALSE)
#Sys.sleep(1.5)
#plot(fit.model , plotfun = "trace",pars="mu", inc_warmup = FALSE)
#Sys.sleep(1.5)
#plot(fit.model , plotfun = "trace",pars="sigma_u", inc_warmup = FALSE)
#Sys.sleep(1.5)
#plot(fit.model , plotfun = "trace",pars="sigma_e", inc_warmup = FALSE)
#Sys.sleep(1.5)
#plot(fit.model , plotfun = "trace",pars="ICC", inc_warmup = FALSE)
#Sys.sleep(1.5)
#
#rhats <- rhat(fit.model)
#ratios <- neff_ratio(fit.model)
#mcmc_rhat(rhats)
#color_scheme_set("purple")
#mcmc_rhat(rhats[1:10], size = 5)
#mcmc_neff(ratios, size = 3)
#attr(ratios[which(ratios<0.1)],"names")
#
##fit_cp = readRDS("fit.rds")
#sampler_params <- get_sampler_params(fit.model, inc_warmup = TRUE)
#summary(do.call(rbind, sampler_params), digits = 2)
#check_divergences(fit.model)
#check_treedepth(fit.model)
#check_energy(fit.model) 





#...beta
jpeg(file=paste(paste("stan_beta",ff),".jpeg"))
plot(density(fit_ss$beta),
     col="blue",main="beta - 95% HPD",xlab="")
ee <- density(fit_ss$beta)
(hdiD <- hdi(ee, allowSplit=TRUE))
(ht <- attr(hdiD, "height"))
segments(hdiD[, 1], ht, hdiD[, 2], ht, lwd=4, col='blue', lend='butt')
abline(h=ht,lty=2,col="blue")
abline(v=c(hdiD[, 1],hdiD[, 2]),lty=2,col="blue")
for(ww in 1:length(hdiD[, 1])){
  l <- min(which(ee$x >= hdiD[ww, 1]))
  h <- max(which(ee$x <= hdiD[ww, 2]))
  polygon(c(ee$x[c(l, l:h, h)]),
          c(0, ee$y[l:h], 0),
          col = "blue",
          density = 10, angle = 45)
}
dev.off()
write.csv(hdiD,file=paste(paste("HPD Intervals stan beta_",ff),".csv"))


#...sigma_u
jpeg(file=paste(paste("stan_sigma_u",ff),".jpeg"))
plot(density((fit_ss$sigma_u)^2),
     col="blue",main="sigma_u - 95% HPD",xlab="")
ee <- density((fit_ss$sigma_u)^2)
(hdiD <- hdi(ee, allowSplit=TRUE))
(ht <- attr(hdiD, "height"))
segments(hdiD[, 1], ht, hdiD[, 2], ht, lwd=4, col='blue', lend='butt')
abline(h=ht,lty=2,col="blue")
abline(v=c(hdiD[, 1],hdiD[, 2]),lty=2,col="blue")
for(ww in 1:length(hdiD[, 1])){
  l <- min(which(ee$x >= hdiD[ww, 1]))
  h <- max(which(ee$x < hdiD[ww, 2]))
  polygon(c(ee$x[c(l, l:h, h)]),
          c(0, ee$y[l:h], 0),
          col = "blue",
          density = 10, angle = 45)
}
#abline(v=true_mixture_var,col="red")
dev.off()
write.csv(hdiD,file=paste(paste("HPD Intervals stan sigma_u_",ff),".csv"))


#sigma_e
jpeg(file=paste(paste("stan_sigma_e",ff),".jpeg"))
plot(density(fit_ss$sigma_e),
     col="blue",main="sigma_e - 95% HPD",xlab="")
ee <- density(fit_ss$sigma_e)
(hdiD <- hdi(ee, allowSplit=TRUE))
(ht <- attr(hdiD, "height"))
segments(hdiD[, 1], ht, hdiD[, 2], ht, lwd=4, col='blue', lend='butt')
abline(h=ht,lty=2,col="blue")
abline(v=c(hdiD[, 1],hdiD[, 2]),lty=2,col="blue")
for(ww in 1:length(hdiD[, 1])){
  l <- min(which(ee$x >= hdiD[ww, 1]))
  h <- max(which(ee$x < hdiD[ww, 2]))
  polygon(c(ee$x[c(l, l:h, h)]),
          c(0, ee$y[l:h], 0),
          col = "blue",
          density = 10, angle = 45)
}
#abline(v=1,col="red")

dev.off()
write.csv(hdiD,file=paste(paste("HPD Intervals stan sigma_e_",ff),".csv"))


#...ICC
jpeg(file=paste(paste("stan_ICC",ff),".jpeg"))
plot(density(fit_ss$ICC),
     col="blue",main="ICC - 95% HPD",xlab="",xaxt = "n")
ee <- density(fit_ss$ICC)
(hdiD <- hdi(ee, allowSplit=TRUE))
(ht <- attr(hdiD, "height"))
segments(hdiD[, 1], ht, hdiD[, 2], ht, lwd=4, col='blue', lend='butt')
#abline(h=ht,lty=2,col="blue")
abline(v=c(hdiD[, 1],hdiD[, 2]),lty=2,col="blue")
axis(1,at=c(round(hdiD[, 1],3),round(hdiD[, 2],3)))
for(ww in 1:length(hdiD[, 1])){
  l <- min(which(ee$x >= hdiD[ww, 1]))
  h <- max(which(ee$x <= hdiD[ww, 2]))
  polygon(c(ee$x[c(l, l:h, h)]),
          c(0, ee$y[l:h], 0),
          col = "blue",
          density = 10, angle = 45)
}
 #abline(v=true_mixture_var/(true_mixture_var+0.4),col="red")
 #abline(v=sample_mixture_var/(sample_mixture_var+var(synt_data$ee)), col="blue")
 #legend("topleft", legend=c("True value", "Sample est"),col=c("red","blue"),lty=1)
dev.off()
write.csv(hdiD,file=paste(paste("HPD Intervals stan ICC_",ff),".csv"))

#...Plot Diagnostics
jpeg(file=paste(paste("Stan_Trace_",ff),".jpeg"))
plot(fit.model, plotfun = "trace", pars = c("beta", "sigma_u", "sigma_e", "ICC"), inc_warmup = TRUE)
dev.off()


##---- approx_ICC 
#par(mfrow=c(1,1))
#jpeg(file=paste(paste("approx_ICC HPD comparison",ff),".jpeg"))
#
#plot(density(fit_ss$ICC),main="",xlab="",xaxt = "n",ylim=c(0,170))
#lines(density(approx_ICC[which (burnIn:nIter %% Thin == 0) + burnIn]))
#ee <- density(fit_ss$ICC)
#(hdiD <- hdi(ee, allowSplit=TRUE))
#(ht <- attr(hdiD, "height"))
##segments(hdiD[, 1], ht, hdiD[, 2], ht, lwd=4, col='blue', lend='butt')
##abline(h=ht,lty=2,col="blue")
##abline(v=c(hdiD[, 1],hdiD[, 2]),lty=2,col="deeppink")
#axis(1,at=c(round(hdiD[, 1],3),round(hdiD[, 2],3)))
#for(ww in 1:length(hdiD[, 1])){
#  l <- min(which(ee$x >= hdiD[ww, 1]))
#  h <- max(which(ee$x <= hdiD[ww, 2]))
#  polygon(c(ee$x[c(l, l:h, h)]),
#          c(0, ee$y[l:h], 0),
#          col = "green",
#          density = 10, angle = 45)
#}
#
#title(main="approx_ICC 90% HPD", cex.main = 1.3, font.main= 4)
#ee <- density(approx_ICC[which (burnIn:nIter %% Thin == 0) + burnIn])
#(hdiD <- hdi(ee, allowSplit=TRUE,credMass = 0.95))
#(ht <- attr(hdiD, "height"))
##segments(hdiD[, 1], ht, hdiD[, 2], ht, lwd=4, col='deeppink', lend='butt')
##abline(h=0,lty=2,col="blue")
#abline(v=c(hdiD[, 1],hdiD[, 2]),lty=2,col="deeppink")
#cex.axis = 0.5
#axis(1,at=c(round(hdiD[, 1],3),round(hdiD[, 2],3)))
#for(ww in 1:length(hdiD[, 1])){
#  l <- min(which(ee$x >= hdiD[ww, 1]))
#  h <- max(which(ee$x <= hdiD[ww, 2]))
#  polygon(c(ee$x[c(l, l:h, h)]),
#          c(0, ee$y[l:h], 0),
#          col = "red",
#          density = 30, angle = 45)
#}
#abline(v=true_mixture_var/(true_mixture_var+0.4),col="red",lty=2,lwd=2)
##abline(v=sample_mixture_var/(sample_mixture_var+var(synt_data$ee)), col="blue")
#
#legend("topright", legend=c("Normal assumption", "DPM"), fill=c("green", "red"),
#       density=c(30, 30), bty="n",border=c("black", "red"),cex=1.3) 
#
#legend("topleft", legend=c("True value"),col=c("red"),lty=2,lwd=2)
#
##--- comparison ♥ 
##--- comparison ♥ 
#plot(density(fit_ss$ICC))
#ee <- density(fit_ss$ICC)
#(hdiD <- hdi(ee, allowSplit=TRUE))
#(ht <- attr(hdiD, "height"))
##segments(hdiD[, 1], ht, hdiD[, 2], ht, lwd=4, col='blue', lend='butt')
##abline(h=ht,lty=2,col="blue")
##abline(v=c(hdiD[, 1],hdiD[, 2]),lty=2,col="deeppink")
#axis(1,at=c(round(hdiD[, 1],3),round(hdiD[, 2],3)))
#for(ww in 1:length(hdiD[, 1])){
#  l <- min(which(ee$x >= hdiD[ww, 1]))
#  h <- max(which(ee$x < hdiD[ww, 2]))
#  polygon(c(ee$x[c(l, l:h, h)]),
#          c(0, ee$y[l:h], 0),
#          col = "green",
#          density = 30, angle = 45)
#}
#
#
#dev.off()

#dev.off()

Sys.sleep(10)
print("STAN done")
setwd("C:/Users/39388/Dropbox/Il mio PC (LAPTOP-NO4UO9GH)/Desktop/Paper_UCL/SMA/Simulation 2")
}


